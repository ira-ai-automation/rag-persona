# Local RAG Assistant - Standalone Software

A fully offline AI assistant that answers questions using your personal documents. No cloud dependency, complete privacy, powered by local LLMs.

## ğŸš€ Quick Start (3 Steps)

### 1. Setup Environment
```bash
# Clone and setup
git clone <your-repo-url>
cd rag-persona
python3 setup.py    # Interactive setup with model download
```

### 2. Index Your Documents
```bash
# For PDF and Word documents from your home directory:
make ingest-home

# OR place documents in data/ folder and run:
make ingest
```

### 3. Start Asking Questions
```bash
make run    # Start CLI assistant
```

That's it! ğŸ‰ Your personal AI assistant is ready.

---

## Problem Statement

Modern professionals and researchers deal with large volumes of unstructured data requiring:
- AI assistant for domain-specific questions
- Offline capabilities for security and privacy
- Personalized knowledge bases reflecting user expertise
- Cost-effective solutions without cloud APIs

## Solution

**Local RAG Assistant** - A fully offline Retrieval-Augmented Generation system operating on a single computer.

## Key Features

### ğŸ”’ Fully Offline
- Runs locally with llama.cpp using quantized LLM models
- No internet dependency once set up
- Complete data privacy and security

### ğŸ—„ï¸ Local Knowledge Base with Vector Search
- FAISS for high-speed document retrieval
- Processes .txt, .md, and .pdf files into embeddings
- Powered by sentence-transformers

### ğŸ¯ Personalized Answers
- Embeds domain knowledge for contextual responses
- Provides source citations for transparency
- Customizable system prompts

### ğŸ” License/Subscription Support
- RSA-based license key generation
- Commercial knowledge sharing capabilities
- Intellectual property protection

### ğŸ–¥ï¸ User-Friendly Interfaces
- CLI for power users
- Streamlit web UI for easy interaction
- RESTful API support

### âš™ï¸ Automation
- Makefile for one-line setup and operations
- Automated model management
- Configuration-driven deployment

## Technical Architecture

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ User Queries   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ RAG Pipeline    â”‚
        â”‚ (Retriever+LLM) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector DB (FAISS)      â”‚  â†â”€â”€ Embeddings (Sentence-Transformers)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Metadata (SQLite)     â”‚  â†â”€â”€ Document Titles, Paths
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Local LLM (llama.cpp) â”‚  â†â”€â”€ Offline LLaMA/Mistral model
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### 1. Setup

**Easy Setup** (recommended - interactive setup with prompts):
```bash
python3 setup.py    # Automated setup with model download options
```

**Manual Setup**:
```bash
make setup          # Install dependencies and create environment
make download-model  # Download recommended model
```

### 2. Index Documents

Choose your scanning mode based on your needs:

**Manual Mode** (default - scan only data/ folder):
```bash
# Place your documents in data/
cp /path/to/your/docs/* data/
make ingest         # Process and index documents
```

**Home Directory Mode** (scan user's home folder):
```bash
make ingest-home    # Index all documents from ~/
```

**System-wide Mode** (scan entire system - requires sudo):
```bash
make ingest-system  # Index documents from entire filesystem
# OR use the dedicated script with safety prompts:
sudo python scripts/system_scan.py
```

**Custom Directories** (configure in settings.yaml):
```bash
# Edit config/settings.yaml to set custom directories
make ingest-custom  # Index from configured directories
```

### 3. Run Assistant
```bash
make run            # Start CLI interface
# OR
make web            # Start web interface
# OR  
make api            # Start API server
```

## Requirements

- Python 3.10+
- 8GB+ RAM recommended
- 10GB+ disk space for models
- macOS/Linux/Windows support

## Project Structure

```
rag-persona/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ Makefile                  # Automation commands
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ config/                   
â”‚   â”œâ”€â”€ settings.yaml         # Main configuration
â”‚   â””â”€â”€ models.yaml          # Model configurations
â”œâ”€â”€ src/                     
â”‚   â”œâ”€â”€ __init__.py          
â”‚   â”œâ”€â”€ core/                # Core RAG implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py     
â”‚   â”‚   â”œâ”€â”€ embedder.py      # Document embedding
â”‚   â”‚   â”œâ”€â”€ retriever.py     # Vector search
â”‚   â”‚   â”œâ”€â”€ generator.py     # LLM interface
â”‚   â”‚   â””â”€â”€ pipeline.py      # Main RAG pipeline
â”‚   â”œâ”€â”€ data/                # Data processing
â”‚   â”‚   â”œâ”€â”€ __init__.py     
â”‚   â”‚   â”œâ”€â”€ loader.py        # Document loading
â”‚   â”‚   â”œâ”€â”€ chunker.py       # Text chunking
â”‚   â”‚   â””â”€â”€ indexer.py       # Index management
â”‚   â”œâ”€â”€ licensing/           # License system
â”‚   â”‚   â”œâ”€â”€ __init__.py     
â”‚   â”‚   â”œâ”€â”€ generator.py     # License generation
â”‚   â”‚   â””â”€â”€ validator.py     # License validation
â”‚   â”œâ”€â”€ interfaces/          # User interfaces
â”‚   â”‚   â”œâ”€â”€ __init__.py     
â”‚   â”‚   â”œâ”€â”€ cli.py           # Command line interface
â”‚   â”‚   â”œâ”€â”€ web.py           # Streamlit web UI
â”‚   â”‚   â””â”€â”€ api.py           # FastAPI REST interface
â”‚   â””â”€â”€ utils/               # Utilities
â”‚       â”œâ”€â”€ __init__.py     
â”‚       â”œâ”€â”€ config.py        # Configuration management
â”‚       â”œâ”€â”€ logging.py       # Logging setup
â”‚       â””â”€â”€ helpers.py       # Helper functions
â”œâ”€â”€ models/                  # LLM models (gitignored)
â”œâ”€â”€ data/                    # Input documents (gitignored)
â”œâ”€â”€ index/                   # Vector index & metadata (gitignored)
â”œâ”€â”€ logs/                    # Application logs (gitignored)
â”œâ”€â”€ licenses/                # License keys (gitignored)
â””â”€â”€ scripts/                 # Utility scripts
    â””â”€â”€ system_scan.py       # System-wide scanning script
```

## License

MIT License - See LICENSE file for details.

## ğŸ“Š Current System Status

âœ… **System Operational**: Successfully indexed 195 documents (290.9 MB)  
âœ… **Document Types**: PDF and Word documents optimized  
âœ… **Index Ready**: Vector database operational with FAISS  
âœ… **Model Downloaded**: Mistral-7B-Instruct-v0.2 (4.1GB) ready  

## ğŸ”§ Available Commands

```bash
# Setup and Installation
make setup              # Manual setup with dependencies
make easy-setup         # Run automated setup.py
python setup.py         # Interactive setup with options

# Model Management  
make download-model     # Download recommended Mistral-7B model
make list-models        # Show downloaded models
make model-info         # Display current model information

# Document Processing
make ingest             # Index documents from data/ folder
make ingest-home        # Index from entire home directory  
make ingest-system      # Index from entire system (requires sudo)
make ingest-custom      # Index from custom directories

# Running the Assistant
make run               # Start CLI interface
make web               # Start Streamlit web interface
make api               # Start FastAPI REST server

# Utilities
make validate          # Validate system configuration
make clean             # Clean temporary files
make clean-all         # Clean everything including models
```

## Support

For issues and questions, please check the documentation or create an issue in the repository.
